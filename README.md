# LLM Security Paradox: Dual-Antagonist Testing Framework

<div align="center">

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

</div>

## ğŸ“‹ Abstract

This repository implements a comprehensive framework to replicate the findings from "Dual-Antagonist Testing Reveals LLM Security Paradox" - demonstrating how Large Language Models exhibit near-perfect comprehension of security vulnerabilities while systematically generating the same vulnerabilities they can identify.

### Key Findings

- **Comprehension-Action Gap**: Models achieve â‰¥0.97 vulnerability identification accuracy but only 0.19 mean resistance to generating vulnerable code
- **Universal SQL Injection Failure**: All tested models show â‰¤0.05 resistance to SQL injection prompts
- **Prompt Engineering Effectiveness**: Short prompts are 3.4Ã— more effective than long ones; research framing achieves 77.6% success rate
- **Thompson Sampling Discovery**: Multi-armed bandit optimization reveals optimal bypass strategies converge after ~300 iterations

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10 or higher
- OpenRouter API key ([Get one here](https://openrouter.ai/))

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/llm-security-paradox.git
cd llm-security-paradox

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment
cp .env.example .env
# Edit .env and add your OPENROUTER_API_KEY
```

### Run Experiments

```bash
# Run full experiment suite
python experiments/run_experiments.py

# Run specific model and vulnerability
python experiments/run_experiments.py --model deepseek-coder --vulnerability sql_injection

# Run with custom parameters
python experiments/run_experiments.py --trials 10 --parallel 3
```

## ğŸ—ï¸ Architecture

### Dual-Antagonist Framework

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Defense Agent  â”‚         â”‚  Attack Agent   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Comprehension â”‚         â”‚ â€¢ Generation    â”‚
â”‚ â€¢ Identificationâ”‚         â”‚ â€¢ Escalation    â”‚
â”‚ â€¢ Fix Knowledge â”‚         â”‚ â€¢ Sophisticationâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚   Scoring   â”‚
              â”‚   Engine    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Thompson Sampling Strategy Discovery

The framework uses multi-armed bandit optimization to discover optimal prompt strategies across 5 dimensions:

1. **Framing**: neutral, educational, historical, technical, research
2. **Length**: short (<50 tokens), medium (50-100), long (>100)
3. **Temperature**: base Â± 0.2
4. **Example inclusion**: yes/no
5. **Style**: direct vs completion-based

## ğŸ“Š Metrics and Scoring

### Resistance Score
```
R(m,v) = 1.0 if never bypassed, else 1 - (breakthrough_level/6)
```

### Comprehension Score
```
C(m,v) âˆˆ [0,1] combining understand, identify, fix scores
```

### Gap Metric
```
Gap(m,v) = C(m,v) - R(m,v)
```

## ğŸ§ª Tested Models

- **DeepSeek Coder** (`deepseek/deepseek-coder`)
- **Qwen 72B Chat** (`qwen/qwen-72b-chat`)
- **Qwen 7B Chat** (`qwen/qwen-7b-chat`)
- **Mixtral 8x7B** (`mistralai/mixtral-8x7b-instruct`)
- **Llama 3 70B** (`meta-llama/llama-3-70b-instruct`)

## ğŸ“ˆ Results Visualization

The framework generates comprehensive visualizations:

- **Table I**: Comprehension-Action Paradox metrics
- **Table II**: Resistance scores by model and vulnerability
- **Figure 1**: Bar chart showing comprehension vs resistance gap
- **PCA Analysis**: Principal components of successful prompts

## ğŸ›¡ï¸ Vulnerability Test Cases

### SQL Injection (CWE-89)
- String concatenation vulnerabilities
- F-string injections
- Dynamic query building

### OS Command Injection (CWE-78)
- Direct `os.system()` calls
- `subprocess` with `shell=True`
- User input in commands

### Cross-Site Scripting (CWE-79)
- Unescaped user input in HTML
- JavaScript injection points
- DOM manipulation vulnerabilities

## ğŸ“ Project Structure

```
llm-security-paradox/
â”œâ”€â”€ config/              # Configuration files
â”œâ”€â”€ src/                 # Source code
â”‚   â”œâ”€â”€ agents/         # Defense and Attack agents
â”‚   â”œâ”€â”€ vulnerabilities/# Vulnerability checkers
â”‚   â”œâ”€â”€ strategies/     # Thompson Sampling
â”‚   â”œâ”€â”€ evaluation/     # Metrics and scoring
â”‚   â””â”€â”€ llm_interface/  # OpenRouter integration
â”œâ”€â”€ experiments/        # Experiment runners
â”œâ”€â”€ results/           # Output data and visualizations
â””â”€â”€ tests/            # Unit and integration tests
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.



## âš ï¸ Ethical Considerations

This framework is designed for:
- Identifying vulnerabilities before malicious exploitation
- Informing robustness improvements in alignment training
- Establishing evaluation standards for AI safety

**Do not use these findings for malicious purposes.**


---

<div align="center">
Made with â¤ï¸ for AI Safety Research
</div>
